## Haja â€” â˜ï¸ Cloud AI Infrastructure Engineer (Starting Jan 2026)

I build and operate AI systems that run in production: retrieval pipelines, evaluation + quality gates, and reliable cloud infrastructure for LLM-backed products. My work is backend-first, with a focus on measurable relevance, performance, and security.

ğŸ” **Focus:** AI platform infrastructure â€¢ Retrieval/RAG â€¢ Performance & security automation â€¢ Resilient deployments  
ğŸ“¬ **Contact:** [LinkedIn](https://www.linkedin.com/in/nurhajjariahk/) â€¢ [Email](mailto:nurhajjariahk@gmail.com)

---

## ğŸ§­ What I work on
- ğŸ§  **AI retrieval infrastructure:** hybrid retrieval (graph + vector + structured filters), indexing, ranking, tuning
- âœ… **Production readiness:** load testing, latency/concurrency modeling, rollout safety checks
- ğŸ” **Security automation:** OWASP ZAP scans wired into repeatable workflows
- ğŸ› ï¸ **Cloud reliability:** active-active patterns, routing, TLS hardening, operational guardrails

---

## ğŸ§° Skills (backend-first, adaptable)
- ğŸ§‘â€ğŸ’» **Backend:** highly adaptable across backend stacks (APIs, services, data pipelines, integrations). This is my primary strength.
- ğŸ¨ **Frontend:** not my focus (I can integrate and support, but I donâ€™t position myself as a frontend specialist).

**Languages:** Python â€¢ TypeScript/JavaScript â€¢ Bash  
**AI/Retrieval:** LangChain â€¢ embeddings pipelines â€¢ hybrid ranking â€¢ evaluation workflows  
**Data/Stores:** Neo4j â€¢ PostgreSQL/pgVector â€¢ TiDB â€¢ MySQL  
**Infra/Delivery:** Docker â€¢ Nginx â€¢ Linux â€¢ active-active deployments  
**Testing/Quality:** k6 â€¢ Locust â€¢ Playwright â€¢ OWASP ZAP

---

## ğŸ›ï¸ Production-grade deployments (publicly accessible)
Most of my production work serves **state government** use cases, so the **codebases are confidential**. Some deployed products are publicly viewable:

- ğŸŒ **Dayang chatbot (Sarawak services portal):** https://service.sarawak.gov.my/web/  
- âš–ï¸ **Court-related project (public article reference):** https://ekss-portal.kehakiman.gov.my/portals/web/home/article_view/0/5/1  
- ğŸ“š **Malaysia public library chatbot (button-based):** https://www.u-library.gov.my/portal/web/guest

---

## ğŸš€ Selected public repositories (engineering examples)
These repos represent the kinds of systems I build (pipeline â†’ retrieval â†’ validation), even when production code is not public:

| Area | Repository | What it shows |
|---|---|---|
| ğŸ¬ Local multi-agent AI app | **agentic-video-analyst** | offline inference + multi-agent orchestration + desktop app engineering |
| ğŸ•¸ï¸ Graph ingestion + retrieval | **neo4j-document-pipeline** | graph modeling + retrieval API patterns for LLM workflows |
| ğŸ“ˆ Vector + hybrid experiments | **tidb-vector-llm-testbed** | relevance/scoring experiments, indexing tradeoffs |
| ğŸ§¬ Embedding pipeline | **mysql-to-pgvector-embeddings** | extraction â†’ embeddings â†’ pgVector semantic layer |
| ğŸ“š Structured retrieval | **faq-retrieval-system** | structured query layer for grounded answers |
| ğŸ§ª Performance testing | **playwright-dayang**, **k6-for-custom-dify** | UX + API load testing approaches for assistants |
| ğŸ›¡ï¸ Security automation | **zap-security-api** | ZAP baseline/quick/full scan exposed via API |
| ğŸ§© Experiments | **playwright-study**, **besu-ibft2.0** | targeted learning repos (testing + distributed systems) |

---

## ğŸ§  How I approach AI systems
- ğŸ“ Prefer **measured improvements** (evaluation + monitoring) over demo-only features  
- â±ï¸ Treat **quality, latency, and security** as release criteria  
- ğŸ” Build systems that are **operable** (clear failure modes, logs/metrics, runbooks)

---

